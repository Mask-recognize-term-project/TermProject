{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 확산 예방을 위한 마스크 착용 감지 소프트웨어 개발"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*2020105721 이시온*  \n",
    "*2020105723 이우일*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 목표 및 내용\n",
    "\n",
    "현재 전세계적으로 가장 큰 문제라고 이야기되는 것은 바로 코로나 19 바이러스 입니다. 이러한 바이러스는 전세계에 많은 사람들의 일상을 빼앗아가고, 수많은 피해자들을 낳았으며 현재 우리는 이전과는 다른 세상을 살아가고 있습니다.\n",
    "이렇게 큰 피해를 준 코로나 19 바이러스를 예방하기에 가장 쉬운 방법은 마스크를 착용하는 것이라고 합니다. 따라서 우리들은 코로나 19 바이러스의 확산을 막고 이 질병이 없었던 시대로 다시 돌아갈 수 있도록 마스크를 착용하고 있는지 여부를 감지하는 소프트웨어를 개발할 계획입니다.\n",
    "이 주제에 대해 조금 더 자세히 설명하자면, 일단 사람의 얼굴을 인식한 후, 그 사람이 마스크를 착용하고 있는지의 여부에 대해서는 당연히 판단을 할 수 있도록 개발할 예정입니다. 또 이에 추가적으로 마스크를 착용하고 있더라도 코를 가리지 않고 입만 가리고 있는지, 혹은 코와 입 모두 가리지 않고 턱에만 걸치고 있는지를 구별하는 소프트웨어를 개발하고자 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주제 변경 이유\n",
    "\n",
    "주제를 변경한 이유는 크게 3가지 입니다.\n",
    "\n",
    "#### ① 이전 주제에서 목표했던 소프트웨어의 분야와 저희가 공통으로 관심있어 하는 분야와의 괴리\n",
    "\n",
    "#### ② 구현 방법에 대한 어려움\n",
    "\n",
    "#### ③ 이전에 목표했던 소프트웨어의 실질적 의미가 크지 않다는 것에 대한 회의감\n",
    "\n",
    "\n",
    "따라서 보다 나은 주제를 찾아보고자 하였고, 공통 관심 분야인 컴퓨터 비전과 관련된 주제를 탐색하게 되었습니다. 또한 저희는 사회적으로 크게 이슈가 되는 분야들에 기여하고 싶다는 생각을 가지고 있었기 때문에 마스크의 착용 여부를 판단해주는 소프트웨어를 개발하는 것으로 주제로 변경하게 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 구현 방법\n",
    "\n",
    "마스크 착용 여부를 판단하는 소프트웨어를 개발하기 위한 방법을 두 가지 정도로 생각해보았습니다.\n",
    "일단 첫번째 방법으로는 dlib을 이용하는 방법입니다. dlib이라는 라이브러리는 얼굴을 탐색하고 인식하는 라이브러리로 이를 이용하면 눈, 코, 입, 눈썹 턱선의 Facial Landmark를 검출할 수 있습니다. 이 점을 활용하여 마스크를 온전히 착용한다면 코와 입, 턱선이 모두 Landmark가 검출되지 않을 것이고, 입과 턱선만 검출되지 않으면 입만 가리도록 마스크를 착용한 경우, 턱선만 검출되지 않으면 턱에만 마스크를 걸친 경우로 판단할 수 있을 것이라고 생각하였습니다.\n",
    "\n",
    "그래서 이 방법을 간단하게 테스트해본 결과, 처음에 생각했던 결과와 다르게 나타나게 되었습니다.\n",
    "마스크를 착용하지 않고 Facial Landmark detection을 한 경우 아래와 같이 모든 부분을 잘 인식합니다.\n",
    "\n",
    "![Facial_Landmark.jpg](Facial_Landmark.jpg)\n",
    "\n",
    "하지만 마스크를 착용하거나 얼굴의 일부분을 가리면 가려진 부분의 Landmark만 인식을 하지 않은 것이 아니라 얼굴의 모든 부분의 Landmark를 인식하지 않는 모습을 보입니다.\n",
    "\n",
    "![Facial_Landmark_mask.jpg](Facial_Landmark_mask.jpg)\n",
    "\n",
    "이렇게 마스크를 착용하면 가린 부분뿐만 아니라 전체의 Facial Landmark를 인식하지 못하기 때문에 첫번째 방법으로는 구현할 수 없다는 것을 깨닫게 되어 다른 방법을 찾아보았습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 목표한 소프트웨어를 개발하기 위해 생각한 두번째 방법으로는 Tensorflow의 keras를 이용하는 방법입니다. keras를 이용하여 컴퓨터를 학습시켜 이미지를 분류해낼 수 있도록 할 계획입니다. 컴퓨터를 학습시키기 위한 데이터셋은 https://github.com/cabani/MaskedFace-Net 이곳에서 제공하고 있는 데이터를 바탕으로 진행할 예정입니다. 이곳에서 제공하는 데이터셋은 마스크를 올바르게 착용한 것과 그렇지 않은 것으로만 분류하고 있기 때문에 이 데이터들을 다시 올바르게 착용한 경우, 입과 턱만 가린 경우, 턱만 가린 경우 그리고 마스크를 아예 착용하지 않은 경우로 다시 분류하여 학습 모델로 사용할 예정입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 전처리 및 데이터 분류 \n",
    "\n",
    "학습 데이터로 사용할 이미지는 다음과 같습니다.\n",
    "\n",
    "![mask_image.jpg](mask_image.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 깃허브 링크에서 제공하는 이미지의 종류는\n",
    "\n",
    "### 1. 마스크를 제대로 착용한 이미지\n",
    "### 2. 마스크를 코가 보이도록 착용한 이미지\n",
    "### 3. 마스크를 코와 입 모두가 보이도록 착용한 이미지\n",
    "### 4. 마스크를 코와 입만 가리고 턱에 걸치지 않게 착용한 이미지\n",
    "\n",
    "이렇게 네 가지 종류가 있었습니다. 각각의 파일이름은 N_Mask, N_Mask_Mouth_Chin, N_Mask_Chin,N_Mask_Nose_Mouth 입니다.(N은 6자리 숫자)\n",
    "후에 구글링을 통해 마스크를 아예 착용하지 않은 이미지까지 가져와 학습 데이터로 사용할 것이고, 이를 제외하면 이미지의 총 갯수는 1944개 입니다. 이 중 4번인 N_Mask_Nose_Mouth는 마스크를 제대로 착용한 것이라고 간주하여, 이 이미지를 제외한 1861개의 이미지를 가지고 전처리를 하였고, train_test_split을 이용해 학습 데이터와 검증 데이터로 나누었습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\00000\\00000_Mask.jpg\n",
      "Mask  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\00000\\00105_Mask.jpg\n",
      "Mask  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\00000\\00210_Mask.jpg\n",
      "Mask  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\00000\\00311_Mask.jpg\n",
      "Mask  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\00000\\00416_Mask.jpg\n",
      "Mask  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\00000\\00519_Mask.jpg\n",
      "Mask  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\00000\\00626_Mask.jpg\n",
      "Mask  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\00000\\00736_Mask.jpg\n",
      "Mask  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\00000\\00840_Mask.jpg\n",
      "Mask  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\00000\\00949_Mask.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\00000\\00000_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\00000\\00122_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\00000\\00249_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\00000\\00363_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\00000\\00488_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\00000\\00607_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\00000\\00732_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\00000\\00850_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\00000\\00983_Mask_Mouth_Chin.jpg\n",
      "Mask_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\00000\\00001_Mask_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\01000\\01001_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\01000\\01123_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\01000\\01250_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\01000\\01381_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\01000\\01509_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\01000\\01628_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\01000\\01761_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\01000\\01882_Mask_Mouth_Chin.jpg\n",
      "Mask_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\01000\\01019_Mask_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\02000\\02000_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\02000\\02123_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\02000\\02251_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\02000\\02372_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\02000\\02490_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\02000\\02619_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\02000\\02739_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\02000\\02862_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\02000\\02988_Mask_Mouth_Chin.jpg\n",
      "Mask_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\02000\\02005_Mask_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\03000\\03000_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\03000\\03123_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\03000\\03243_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\03000\\03366_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\03000\\03488_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\03000\\03619_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\03000\\03744_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\03000\\03868_Mask_Mouth_Chin.jpg\n",
      "Mask_Mouth_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\03000\\03996_Mask_Mouth_Chin.jpg\n",
      "Mask_Chin  :  C:\\Users\\Sion\\Desktop\\1-2 자료\\train(O)\\03000\\03007_Mask_Chin.jpg\n",
      "--------------------\n",
      "이미지 갯수 : 4490\n",
      "라벨 갯수 : 4490\n",
      "이미지 학습 데이터 갯수 : 4041\n",
      "이미지 검증 데이터 갯수 : 449\n",
      "라벨 학습 데이터 갯수 : 4041\n",
      "라벨 검증 데이터 갯수 : 449\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "img_dir = 'C:\\\\Users\\\\Sion\\\\Desktop\\\\1-2 자료\\\\train(O)' # 이미지들이 모여있는 파일 이름(000000)\n",
    "categories = ['Mask','Mask_Mouth_Chin','Mask_Chin'] # 마스크 여부 카테고리 (후에 아예 마스크를 안 낀 카테고리도 추가 예정)\n",
    "img_dir_2 = ['00000','01000','02000','03000']\n",
    "\n",
    "# 64x64 이미지로 변경\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for k in img_dir_2:\n",
    "    img_dir_specf = img_dir + '\\\\' + k\n",
    "\n",
    "    for num,categ in enumerate(categories):\n",
    "        file_path = glob.glob(img_dir_specf+'\\\\'+'?????_'+categ+'.jpg') # Massk 제대로 낀 것 부터 차례대로 그 위치 나열\n",
    "    \n",
    "        for i,f in enumerate(file_path):\n",
    "            img = Image.open(f)\n",
    "            img = img.convert(\"RGB\")\n",
    "            img = img.resize((image_w, image_h)) # 64x64 이미지로 변경\n",
    "            data = np.asarray(img)\n",
    "            images.append(data) # numpy형태로 변환한 마스크 사진들\n",
    "            labels.append(num) # X 사진들의 라벨(0,1,2는 각각 'Mask','Mask_Mouth_Chin','Mask_Chin'를 가리킴)\n",
    "        \n",
    "        #진행상황 알려주는 코드\n",
    "            if i % 100 == 0: \n",
    "                print(categ, \" : \", f)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "print('-'*20)\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# X,Y 길이 같은지 점검\n",
    "print('이미지 갯수 :', len(images))\n",
    "print('라벨 갯수 :', len(labels))\n",
    "\n",
    "# training 세트와 test 세트 비율 0.1\n",
    "images_train, images_test, labels_train, labels_test = train_test_split(images, labels, test_size=0.1,random_state=123)\n",
    "\n",
    "# 각각의 길이 확인\n",
    "print('이미지 학습 데이터 갯수 :', len(images_train))\n",
    "print('이미지 검증 데이터 갯수 :', len(images_test))\n",
    "print('라벨 학습 데이터 갯수 :', len(labels_train))\n",
    "print('라벨 검증 데이터 갯수 :', len(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4041, 64, 64, 3)\n",
      "(4041,)\n",
      "[1 1 1 1 1 0 1 1 0 1 0 1 0 2 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1\n",
      " 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 2 0 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 0 1 0\n",
      " 1 0 1 1 2 1 1 1 1 1 0 0 1 1 2 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 2\n",
      " 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 2 2 1 1 1 1 0 1 1 2 1 1 0 1 2 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 0 0 0 1 0 1 2 1 1 0 1 1 2 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 2 1 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 2 1 1 1 1 1 2 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1\n",
      " 0 2 1 1 1 2 1 1 0 1 1 0 1 0 1 0 1 1 2 1 0 1 1 1 0 1 1 1 1 1 0 1 2 1 1 0 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 2 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 2 1 1 1\n",
      " 1 2 2 1 1 0 0 1 1 2 1 1 2 0 1 0 0 1 1 1 1 1 1 1 2 1 1 0 1 0 0 1 1 1 1 1 0\n",
      " 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1\n",
      " 1 1 2 1 0 1 1 1 1 1 1 1 2 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 2 1 0 1\n",
      " 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 2 2 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 2 0 1 2 1 1 1 1 1 0 0 1 1 0 1 1 1 1]\n",
      "[[[177 220 254]\n",
      "  [178 221 253]\n",
      "  [178 221 253]\n",
      "  ...\n",
      "  [186 226 254]\n",
      "  [186 225 254]\n",
      "  [186 225 254]]\n",
      "\n",
      " [[178 221 253]\n",
      "  [179 221 253]\n",
      "  [179 222 254]\n",
      "  ...\n",
      "  [188 227 253]\n",
      "  [187 226 254]\n",
      "  [186 226 254]]\n",
      "\n",
      " [[179 222 254]\n",
      "  [181 222 254]\n",
      "  [182 223 254]\n",
      "  ...\n",
      "  [190 227 254]\n",
      "  [188 227 254]\n",
      "  [187 227 254]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[205 235 254]\n",
      "  [206 236 255]\n",
      "  [208 236 255]\n",
      "  ...\n",
      "  [ 83  66  54]\n",
      "  [107  91  78]\n",
      "  [ 93  74  67]]\n",
      "\n",
      " [[205 235 255]\n",
      "  [206 236 254]\n",
      "  [207 236 255]\n",
      "  ...\n",
      "  [117  98  82]\n",
      "  [128 113  98]\n",
      "  [146 138 124]]\n",
      "\n",
      " [[205 236 255]\n",
      "  [204 235 254]\n",
      "  [207 236 255]\n",
      "  ...\n",
      "  [151 128 106]\n",
      "  [155 131 109]\n",
      "  [152 128 108]]]\n"
     ]
    }
   ],
   "source": [
    "# 이미지 형태\n",
    "print(images_train.shape)\n",
    "print(labels_train.shape)\n",
    "print(labels_train[3500:4040])\n",
    "print(images_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 CNN을 이용하기 위해 keras의 Conv2D를 이용할 것이고, 위 데이터들을 이용해 학습시킬 것입니다. 이렇게 학습시킨 후 OpenCV 라이브러리를 이용하여 사람의 얼굴을 카메라 내장 카메라를 통해 인식하고, 인식한 얼굴을 바탕으로 마스크 착용 여부를 감지하도록 소프트웨어를 개발할 계획입니다. \n",
    "\n",
    "시간관계상 학습 데이터량을 많이 준비하지 못했지만, 만약 keras를 이용해 만든 마스크 인식 모델의 정확도가 80% 미만이라면 이미지 데이터의 양을 2배 이상 늘리고 마스크를 아예 끼지 않은 사진까지도 그렇게 하여 인식도를 높일 예정입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = images_train.astype('float32') / 255\n",
    "images_test = images_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(images_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=images_train.shape[1:],activation=\"relu\"))\n",
    "#model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=(64,64,1) ,activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model_dir = '.\\\\model'\n",
    "model_path = model_dir + '\\\\'+'mask_detection.model'\n",
    "checkpoint = ModelCheckpoint(filepath =model_path,monitor='val_loss',verbose=1,save_best_only=True)\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_94 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_92 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_93 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_94 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_95 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 328,739\n",
      "Trainable params: 328,739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.7470 - accuracy: 0.7146\n",
      "Epoch 00001: val_loss improved from inf to 0.39235, saving model to .\\model\\mask_detection.model\n",
      "INFO:tensorflow:Assets written to: .\\model\\mask_detection.model\\assets\n",
      "54/54 [==============================] - 12s 216ms/step - loss: 0.7470 - accuracy: 0.7146 - val_loss: 0.3923 - val_accuracy: 0.9226\n",
      "Epoch 2/3\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1880 - accuracy: 0.9336\n",
      "Epoch 00002: val_loss improved from 0.39235 to 0.07825, saving model to .\\model\\mask_detection.model\n",
      "INFO:tensorflow:Assets written to: .\\model\\mask_detection.model\\assets\n",
      "54/54 [==============================] - 12s 215ms/step - loss: 0.1880 - accuracy: 0.9336 - val_loss: 0.0783 - val_accuracy: 0.9736\n",
      "Epoch 3/3\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9630\n",
      "Epoch 00003: val_loss improved from 0.07825 to 0.05557, saving model to .\\model\\mask_detection.model\n",
      "INFO:tensorflow:Assets written to: .\\model\\mask_detection.model\\assets\n",
      "54/54 [==============================] - 12s 218ms/step - loss: 0.0978 - accuracy: 0.9630 - val_loss: 0.0556 - val_accuracy: 0.9819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20610ffebc8>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(images_train, labels_train, batch_size=64, epochs=3, validation_split=0.15, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0693 - accuracy: 0.9733\n",
      "accuracy : 97.32739329338074%\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy : {}%\".format(100*(model.evaluate(images_test, labels_test)[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#model_dir = './model'\n",
    "#if not os.path.exists(model_dir):\n",
    "#    os.mkdir(model_dir)\n",
    "#model_path = model_dir + \"/mask_classify.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(path):\n",
    "    X=[]\n",
    "    img = Image.open(path)\n",
    "    img = img.convert(\"RGB\")\n",
    "    img = img.resize((64,64))\n",
    "    data = np.asarray(img)\n",
    "    X.append(data)\n",
    "    X = np.array(X)\n",
    "    X = X.astype('float32')/255\n",
    "    return X\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.858 0.061 0.081]]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(generator('C:\\\\Users\\\\Sion\\\\Desktop\\\\1-2 자료\\\\train(new)\\\\unnamed.jpg'))\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 활동 내역\n",
    "\n",
    "https://github.com/Mask-recognize-term-project/TermProject"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
